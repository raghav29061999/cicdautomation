ðŸ”¹ Opening â€“ Quick Refresher on A2A
"Let me begin with a quick refresher on the A2A protocol, or Agent-to-Agent protocol. At its core, A2A is a communication standard designed to facilitate structured, stateful, and interoperable interactions between autonomous agents or between agents and clients. It introduces a standardized way to define agent capabilities, communicate tasks, manage state, and support multi-modal, multi-turn conversationsâ€”optionally powered by LLMs or deterministic logic.

The Python SDK for A2A helps us scaffold and deploy such agents rapidly while remaining fully compliant with the A2A specification."

ðŸ”¹ Part 1 â€“ HelloWorld A2A Agent Demo
"The first demo is a minimal but complete A2A implementation, aptly called the HelloWorld Agent.

Hereâ€™s how the architecture works:

Agent Skill Definition:
Every A2A agent must explicitly declare its capabilities. This is encapsulated in an AgentSkill object. For HelloWorld, the skill is defined with an ID of hello_world, a description, input/output media types (text/plain in this case), and examples. This acts as a semantic contractâ€”informing any client what this agent can handle.

Agent Card Declaration:
The agent card, a structured JSON exposed at /.well-known/agent.json, is the digital identity of the agent. It includes metadata like the agent's name, version, capabilities (like streaming), and an array of declared skills.
For authenticated setups, an extended agent card can also be definedâ€”offering richer capabilities to privileged clients.

Agent Executor:
This is the logical bridge between the A2A server's orchestration layer and our domain-specific logic.
The HelloWorldAgentExecutor implements AgentExecutor and handles the lifecycle of incoming A2A requests via its execute() method.
In this case, it delegates the task to a simple agent class which returns the string "Hello World", which is then wrapped in a Message event and sent back via the event queue.

Server Initialization:
Using the A2AStarletteApplication class, the server is bootstrapped with the agent card and the DefaultRequestHandler, which binds the executor and task store (an InMemoryTaskStore in this case).
It's launched using uvicorn, listening on port 9999.

Client Interaction:
A simple test client retrieves the agent card, initializes the A2AClient, and sends a SendMessageRequest containing a user message.
The server responds with a plain message event: 'Hello World'.

This setup illustrates the end-to-end request-response lifecycle and the structure A2A enforcesâ€”from discovery, to capability negotiation, to response handlingâ€”all in a stateless form."

ðŸ”¹ Part 2 â€“ Advanced LangGraph Agent with Streaming & Multi-Turn Support
"Now letâ€™s look at a more sophisticated example that pushes the boundaries of what A2A supportsâ€”a LangGraph-powered Currency Agent integrating a Large Language Model, specifically Google Gemini.

This agent demonstrates three major enhancements over HelloWorld:

LLM Integration with LangChain + LangGraph:
The CurrencyAgent internally uses ChatGoogleGenerativeAI via LangChain, orchestrated through LangGraphâ€™s ReAct-style flow.
This means the agent can reason, call tools like get_exchange_rate, and respond based on intermediate results.

Task State Management:
Unlike HelloWorld, this agent returns a full Task object, supporting multi-turn interactions and streaming.
The CurrencyAgentExecutor inspects the incoming RequestContext to determine if itâ€™s a follow-up message or a new interaction and maintains continuity using TaskStore.

Streaming & Multi-Turn Eventing:
The executor emits intermediate updates via TaskStatusUpdateEvent and returns the final result using TaskArtifactUpdateEvent.
If clarification is needed, it sends an event with TaskState.input_required, asking the client for more input. This illustrates asynchronous back-and-forth using a single logical task.

Iâ€™ve also created a custom CLI wrapper that leverages A2ACardResolver and A2AClient to send dynamic questions to this agent. This tool allows me to query the Currency Agent like:

bash
Copy
Edit
python cli_test.py --question "100 USD in EUR"
The server then responds with a streamed or structured message depending on the complexity of the query.

All server-side orchestration remains compliant with the A2A protocolâ€”exposing the same /agent.json endpoint, supporting authenticated access, and enforcing clean message schema definitions."

ðŸ”¹ Closing â€“ Why This Matters
"Together, these two demos show the full spectrum of A2A agent designâ€”from a minimal stateless agent to a fully stateful, LLM-integrated agent with streaming and memory.

The Agent Card provides discoverability and feature introspection.
The Agent Skill defines scoped capabilities.
The Agent Executor acts as the bridge between protocol-level abstraction and agent-specific intelligence.
And the A2A Server and Client SDKs allow us to implement and test these capabilities quickly, with clean separation of concerns.

This positions A2A as a powerful foundation for building scalable, composable, and interoperable AI agentsâ€”ready for complex real-world applications, whether in tooling automation, enterprise workflows, or agentic collaboration."

